{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ehDZers214IV"},"outputs":[],"source":["import zipfile\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","# Unzip training data\n","#zip_ref = zipfile.ZipFile('/content/drive/Shareddrives/OpenMonkeyChallenge/train.zip', 'r')\n","#zip_ref.extractall('/content/data')\n","#zip_ref.close()\n","\n","# Unzip validation data\n","zip_ref = zipfile.ZipFile('/content/drive/Shareddrives/OpenMonkeyChallenge/val.zip', 'r')\n","zip_ref.extractall('/content/data')\n","zip_ref.close()\n","\n","# Unzip testing data\n","#zip_ref = zipfile.ZipFile('/content/drive/MyDrive/Colab/test.zip', 'r')\n","#zip_ref.extractall('/content/data')\n","#zip_ref.close()"]},{"cell_type":"code","source":["import json\n","from PIL import Image\n","from torch.utils.data import Dataset\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as f\n","import matplotlib.pyplot as plt\n","\n","cuda = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","input_size = 368\n","output_size = input_size // 8\n","species = ['Rhesus_macaque', 'Olive_baboon', 'Gibbon', 'Golden_lion_tamarin', 'Common_marmoset', 'Bonobo', 'Siamang', 'Crab-eating_macaque', 'Vervet_monkey', 'Orangutan', 'Gorilla', 'Chacma_baboon', 'Chimpanzee', 'Golden_snub-nosed_monkey', 'Hamadryas_baboon', 'Cotton-top_tamarin', 'Proboscis_monkey', 'Barbary_macaque', 'Dusky_leaf_monkey', 'Squirrel_monkey', 'Emperor_tamarin', 'Tufted_capuchin', 'Mandrill', 'Lion-tailed_macaque', 'Formosan_rock_macaque', 'Japanese_macaque']\n","num_species = len(species)\n","apes = ['Gibbon', 'Siamang', 'Bonobo', 'Orangutan', 'Gorilla', 'Chimpanzee']\n","new_world = ['Golden_lion_tamarin', 'Common_marmoset', 'Emperor_tamarin', 'Tufted_capuchin', 'Cotton-top_tamarin', 'Squirrel_monkey']\n","old_world = ['Rhesus_macaque', 'Olive_baboon', 'Crab-eating_macaque', 'Vervet_monkey', 'Chacma_baboon', 'Golden_snub-nosed_monkey', 'Hamadryas_baboon', 'Proboscis_monkey', 'Barbary_macaque', 'Dusky_leaf_monkey', 'Mandrill', 'Lion-tailed_macaque', 'Formosan_rock_macaque', 'Japanese_macaque']\n","\n","class OpenMonkeyDataset(Dataset):\n","    def __init__(self, images_root, annotations_path, input_size, output_size, c = None):\n","        super().__init__()\n","        self.images_root = images_root\n","        file = open(annotations_path)\n","        self.annotations = json.load(file)\n","        file.close()\n","        if c == 'ape':\n","          self.annotations['data'] = [self.annotations['data'][i] for i in range(len(self.annotations['data'])) if self.annotations['data'][i]['species'] in apes]\n","        elif c == 'new_world':\n","          self.annotations['data'] = [self.annotations['data'][i] for i in range(len(self.annotations['data'])) if self.annotations['data'][i]['species'] in new_world]\n","        elif c == 'old_world':\n","          self.annotations['data'] = [self.annotations['data'][i] for i in range(len(self.annotations['data'])) if self.annotations['data'][i]['species'] in old_world]\n","        self.convert = transforms.ToTensor()\n","        self.normalize = transforms.Normalize((0.4954, 0.4718, 0.4286), (0.2471, 0.2424, 0.2512))\n","        self.resize_in = transforms.Resize((input_size, input_size))\n","        self.resize_out = transforms.Resize((output_size, output_size))\n","        self.gaussian = transforms.GaussianBlur((51, 51), 9.0)\n","\n","    def __len__(self):\n","        return len(self.annotations['data'])\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        cuda = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","        # Create images\n","        image = Image.open(self.images_root + self.annotations['data'][idx]['file'])\n","        image = self.convert(image).to(cuda)\n","        c, h, w = image.size()\n","        image = self.normalize(image)\n","        bbox = self.annotations['data'][idx]['bbox']\n","        image = self.resize_in(image[:, bbox[1] : bbox[1] + bbox[3], bbox[0] : bbox[0] + bbox[2]])\n","\n","        # Create ground truth belief images\n","        gt_belief_images = torch.zeros((18, 1, h, w), device = cuda)\n","        labels = self.annotations['data'][idx]['landmarks']\n","        for j in range(17):\n","            gt_belief_images[j, :, labels[2 * j + 1] - 1, labels[2 * j] - 1] = 275.0\n","        gt_belief_images = self.gaussian(gt_belief_images)[:, 0, :, :]\n","        gt_belief_images = self.resize_out(gt_belief_images[:, bbox[1] : bbox[1] + bbox[3], bbox[0] : bbox[0] + bbox[2]])\n","        gt_belief_images[17, :, :] = f.threshold(1.0 - torch.sum(gt_belief_images[0:17, :, :], 0), 0.0, 0.0)\n","        return (image, gt_belief_images)\n","\n","    def get_original(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        cuda = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","        image = Image.open(self.images_root + self.annotations['data'][idx]['file'])\n","        image = self.convert(image).to(cuda)\n","        landmarks = torch.tensor(self.annotations['data'][idx]['landmarks'], dtype = torch.float)\n","        return (image, landmarks)\n","\n","class Stage1Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv1 = nn.Conv2d(3, 96, 9, padding = 'same')\n","        self.conv2 = nn.Conv2d(96, 256, 9, padding = 'same')\n","        self.conv3 = nn.Conv2d(256, 384, 9, padding = 'same')\n","        self.conv4 = nn.Conv2d(384, 384, 5, padding = 'same')\n","        self.conv5 = nn.Conv2d(384, 256, 9, padding = 'same')\n","        self.conv6 = nn.Conv2d(256, 256, 1, padding = 'same')\n","        self.conv7 = nn.Conv2d(256, 18, 1, padding = 'same')\n","\n","    def forward(self, x):\n","        x = self.pool(f.relu(self.conv1(x)))\n","        x = self.pool(f.relu(self.conv2(x)))\n","        x = self.pool(f.relu(self.conv3(x)))\n","        x = f.relu(self.conv4(x))\n","        x = f.relu(self.conv5(x))\n","        x = f.relu(self.conv6(x))\n","        x = self.conv7(x)\n","        return x\n","\n","class StageTNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv1 = nn.Conv2d(3, 96, 9, padding = 'same')\n","        self.conv2 = nn.Conv2d(96, 256, 9, padding = 'same')\n","        self.conv3 = nn.Conv2d(256, 384, 9, padding = 'same')\n","        self.conv4 = nn.Conv2d(384, 384, 5, padding = 'same')\n","        self.conv5 = nn.Conv2d(402, 402, 11, padding = 'same')\n","        self.conv6 = nn.Conv2d(402, 256, 11, padding = 'same')\n","        self.conv7 = nn.Conv2d(256, 256, 11, padding = 'same')\n","        self.conv8 = nn.Conv2d(256, 256, 1, padding = 'same')\n","        self.conv9 = nn.Conv2d(256, 18, 1, padding = 'same')\n","\n","    def forward(self, x, belief_images):\n","        x = self.pool(f.relu(self.conv1(x)))\n","        x = self.pool(f.relu(self.conv2(x)))\n","        x = self.pool(f.relu(self.conv3(x)))\n","        x = f.relu(self.conv4(x))\n","        x = torch.cat((x, belief_images.detach()), 0 if len(belief_images.size()) == 3 else 1)\n","        x = f.relu(self.conv5(x))\n","        x = f.relu(self.conv6(x))\n","        x = f.relu(self.conv7(x))\n","        x = f.relu(self.conv8(x))\n","        x = self.conv9(x)\n","        return x"],"metadata":{"id":"mwUcLWMaro2y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TRAINING**"],"metadata":{"id":"EIj1VM7QXHYD"}},{"cell_type":"code","source":["trainset = OpenMonkeyDataset('/content/data/train/', '/content/drive/Shareddrives/OpenMonkeyChallenge/train_annotation.json', input_size, output_size, 'old_world')\n","trainloader = DataLoader(trainset, batch_size = 16, shuffle = True, num_workers = 0)\n","valset = OpenMonkeyDataset('/content/data/val/', '/content/drive/Shareddrives/OpenMonkeyChallenge/val_annotation.json', input_size, output_size, 'old_world')\n","valloader = DataLoader(valset, batch_size = 16, shuffle = True, num_workers = 0)\n","\n","stage1 = Stage1Net().to(cuda)\n","optimizer1 = torch.optim.SGD(stage1.parameters(), lr = 1e-7, momentum = 0.9)\n","stage2 = StageTNet().to(cuda)\n","optimizer2 = torch.optim.SGD(stage2.parameters(), lr = 1e-7, momentum = 0.9)\n","stage3 = StageTNet().to(cuda)\n","optimizer3 = torch.optim.SGD(stage3.parameters(), lr = 1e-7, momentum = 0.9)\n","criterion = nn.MSELoss(reduction = 'sum')\n","stage1.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/old_world_stage1.pth'))\n","stage2.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/old_world_stage2.pth'))\n","stage3.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/old_world_stage3.pth'))\n","for epoch in range(100):\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        images, gt_belief_images = data\n","\n","        # Stage 1 forward\n","        optimizer1.zero_grad()\n","        belief_images = stage1.forward(images)\n","        loss1 = criterion(belief_images, gt_belief_images)\n","\n","        # Stage 2 forward\n","        optimizer2.zero_grad()\n","        belief_images = stage2.forward(images, belief_images)\n","        loss2 = criterion(belief_images, gt_belief_images)\n","\n","        # Stage 3 forward\n","        optimizer3.zero_grad()\n","        belief_images = stage3.forward(images, belief_images)\n","        loss3 = criterion(belief_images, gt_belief_images)\n","\n","        # All stages backward + optimize\n","        losses = loss1 + loss2 + loss3\n","        losses.backward()\n","        running_loss += losses.item()\n","        optimizer1.step()\n","        optimizer2.step()\n","        optimizer3.step()\n","\n","        # Print statistics\n","        if i % 100 == 99:\n","            print(\"%d, %d, %f\" %(epoch + 1, i + 1, running_loss / 100))\n","            running_loss = 0.0\n","            plt.imshow(belief_images[0][0].detach().cpu(), vmin = 0.0, vmax = 1.0)\n","            plt.show()\n","            plt.imshow(gt_belief_images[0][0].cpu())\n","            plt.show()\n","            plt.imshow(belief_images[0][17].detach().cpu(), vmin = 0.0, vmax = 1.0)\n","            plt.show()\n","            plt.imshow(gt_belief_images[0][17].cpu())\n","            plt.show()\n","\n","    # Validation\n","    torch.save(stage1.state_dict(), '/content/drive/Shareddrives/OpenMonkeyChallenge/' + str(epoch) + 'old_world_stage1.pth')\n","    torch.save(stage2.state_dict(), '/content/drive/Shareddrives/OpenMonkeyChallenge/' + str(epoch) + 'old_world_stage2.pth')\n","    torch.save(stage3.state_dict(), '/content/drive/Shareddrives/OpenMonkeyChallenge/' + str(epoch) + 'old_world_stage3.pth')\n","    with torch.no_grad():\n","        running_loss = 0.0\n","        for i, data in enumerate(valloader, 0):\n","            images, gt_belief_images = data\n","            belief_images = stage1(images)\n","            loss1 = criterion(belief_images, gt_belief_images)\n","            belief_images = stage2(images, belief_images)\n","            loss2 = criterion(belief_images, gt_belief_images)\n","            belief_images = stage3(images, belief_images)\n","            loss3 = criterion(belief_images, gt_belief_images)\n","            losses = loss1 + loss2 + loss3\n","            running_loss += losses.item()\n","    print(\"%d, %f\" %(epoch + 1, running_loss / i))"],"metadata":{"id":"vB3lkRaSdrMv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**TESTING**"],"metadata":{"id":"EgvANdFVXEyO"}},{"cell_type":"code","source":["from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n","\n","valset = OpenMonkeyDataset('/content/data/val/', '/content/drive/Shareddrives/OpenMonkeyChallenge/val_annotation.json', input_size, output_size)\n","detector = fasterrcnn_resnet50_fpn().to(cuda)\n","in_features = detector.roi_heads.box_predictor.cls_score.in_features\n","detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_species).to(cuda)\n","detector.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/detector.pth'))\n","\n","stage1 = Stage1Net().to(cuda)\n","stage2 = StageTNet().to(cuda)\n","stage3 = StageTNet().to(cuda)\n","stage1.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/base_stage1.pth'))\n","stage2.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/base_stage2.pth'))\n","stage3.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/base_stage3.pth'))\n","\n","stage1.eval()\n","stage2.eval()\n","stage3.eval()\n","detector.eval()\n","normalize = transforms.Normalize((0.4954, 0.4718, 0.4286), (0.2471, 0.2424, 0.2512))\n","mpjpe = torch.zeros((valset.__len__(), 17))\n","with torch.no_grad():\n","    for i in range(valset.__len__()): # Iterate over samples\n","      bbox_gt = valset.annotations['data'][i]['bbox']\n","      label_gt = valset.annotations['data'][i]['species']\n","      \n","      image_orig, landmarks = valset.get_original(i)\n","      results = detector(image_orig[None, :, :, :])\n","      if results[0]['boxes'].size()[0] == 0:\n","        c, img_h, img_w = image_orig.size()\n","        bbox = torch.tensor([3 * img_w / 8, 3 * img_h / 8, 5 * img_w / 8, 5 * img_h / 8]).to(torch.long)\n","        label = torch.randint(num_species, (1,))\n","      else:\n","        bbox = results[0]['boxes'][0].to(torch.long)\n","        label = species[results[0]['labels'][0]]\n","      h = bbox[3] - bbox[1]\n","      w = bbox[2] - bbox[0]\n","      input = normalize(image_orig)\n","      input = input[:, bbox[1] : bbox[3], bbox[0] : bbox[2]]\n","      belief_images = stage1(input)\n","      belief_images = stage2(input, belief_images)\n","      belief_images = stage3(input, belief_images)\n","      resize = transforms.Resize((h, w))\n","      resized = resize(belief_images)\n","      for j in range(17): # Iterate over landmarks\n","        indices = torch.cartesian_prod(torch.arange(h), torch.arange(w)).to(cuda)\n","        indices = torch.stack([indices[j : j + w] for j in range(0, h * w, w)])\n","        softmax = f.softmax(resized[j].view(h * w) * 1000, dim = 0).view(h, w)\n","        bbox_pos = torch.tensor([torch.sum(softmax * indices[:, :, 1]), torch.sum(softmax * indices[:, :, 0])]).to(torch.long)\n","        pos = bbox_pos + torch.tensor([bbox[0], bbox[1]])\n","        mpjpe[i, j] = torch.linalg.norm(pos - landmarks[2 * j : 2 * j + 2]) / bbox_gt[2]\n","    torch.save(mpjpe, '/content/drive/Shareddrives/OpenMonkeyChallenge/mpjpe.pt')"],"metadata":{"id":"IcMvEseHXD-Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**CLASS TESTING**"],"metadata":{"id":"teTYJECdXRRR"}},{"cell_type":"code","source":["from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n","\n","valset = OpenMonkeyDataset('/content/data/val/', '/content/drive/Shareddrives/OpenMonkeyChallenge/val_annotation.json', input_size, output_size)\n","detector = fasterrcnn_resnet50_fpn().to(cuda)\n","in_features = detector.roi_heads.box_predictor.cls_score.in_features\n","detector.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_species).to(cuda)\n","detector.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/detector.pth'))\n","detector.eval()\n","\n","# Ape\n","ape1 = Stage1Net().to(cuda)\n","ape2 = StageTNet().to(cuda)\n","ape3 = StageTNet().to(cuda)\n","ape1.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/ape_stage1.pth'))\n","ape2.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/ape_stage2.pth'))\n","ape3.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/ape_stage3.pth'))\n","ape1.eval()\n","ape2.eval()\n","ape3.eval()\n","\n","# New World\n","new1 = Stage1Net().to(cuda)\n","new2 = StageTNet().to(cuda)\n","new3 = StageTNet().to(cuda)\n","new1.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/new_world_stage1.pth'))\n","new2.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/new_world_stage2.pth'))\n","new3.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/new_world_stage3.pth'))\n","new1.eval()\n","new2.eval()\n","new3.eval()\n","\n","# Old World\n","old1 = Stage1Net().to(cuda)\n","old2 = StageTNet().to(cuda)\n","old3 = StageTNet().to(cuda)\n","old1.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/old_world_stage1.pth'))\n","old2.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/old_world_stage2.pth'))\n","old3.load_state_dict(torch.load('/content/drive/Shareddrives/OpenMonkeyChallenge/old_world_stage3.pth'))\n","old1.eval()\n","old2.eval()\n","old3.eval()\n","\n","normalize = transforms.Normalize((0.4954, 0.4718, 0.4286), (0.2471, 0.2424, 0.2512))\n","mpjpe = torch.zeros((valset.__len__(), 17))\n","with torch.no_grad():\n","    for i in range(valset.__len__()): # Iterate over samples\n","      bbox_gt = valset.annotations['data'][i]['bbox']\n","      label_gt = valset.annotations['data'][i]['species']\n","      \n","      image_orig, landmarks = valset.get_original(i)\n","      results = detector(image_orig[None, :, :, :])\n","      if results[0]['boxes'].size()[0] == 0:\n","        c, img_h, img_w = image_orig.size()\n","        bbox = torch.tensor([3 * img_w / 8, 3 * img_h / 8, 5 * img_w / 8, 5 * img_h / 8]).to(torch.long)\n","        label = torch.randint(num_species, (1,))\n","      else:\n","        bbox = results[0]['boxes'][0].to(torch.long)\n","        label = species[results[0]['labels'][0]]\n","      if label in apes:\n","        stage1 = ape1\n","        stage2 = ape2\n","        stage3 = ape3\n","      elif label in new_world:\n","        stage1 = new1\n","        stage2 = new2\n","        stage3 = new3\n","      else:\n","        stage1 = old1\n","        stage2 = old2\n","        stage3 = old3\n","      h = bbox[3] - bbox[1]\n","      w = bbox[2] - bbox[0]\n","      input = normalize(image_orig)\n","      input = input[:, bbox[1] : bbox[3], bbox[0] : bbox[2]]\n","      belief_images = stage1(input)\n","      belief_images = stage2(input, belief_images)\n","      belief_images = stage3(input, belief_images)\n","      resize = transforms.Resize((h, w))\n","      resized = resize(belief_images)\n","      #bbox_positions = torch.zeros((17, 2))\n","      for j in range(17): # Iterate over landmarks\n","        indices = torch.cartesian_prod(torch.arange(h), torch.arange(w)).to(cuda)\n","        indices = torch.stack([indices[j : j + w] for j in range(0, h * w, w)])\n","        softmax = f.softmax(resized[j].view(h * w) * 1000, dim = 0).view(h, w)\n","        bbox_pos = torch.tensor([torch.sum(softmax * indices[:, :, 1]), torch.sum(softmax * indices[:, :, 0])]).to(torch.long)\n","        pos = bbox_pos + torch.tensor([bbox[0], bbox[1]])\n","        mpjpe[i, j] = torch.linalg.norm(pos - landmarks[2 * j : 2 * j + 2]) / bbox_gt[2]\n","\n","        # Belief Image Visualization\n","        #bbox_positions[j, 0] = bbox_pos[0]\n","        #bbox_positions[j, 1] = bbox_pos[1]\n","        #plt.imshow(image_orig[:, bbox[1] : bbox[3], bbox[0] : bbox[2]].movedim(0, 2).cpu())\n","        #plt.imshow(resized[j].cpu(), cmap = 'jet', vmin = 0.0, vmax = 1.0, alpha = 0.5)\n","        #plt.show()\n","\n","      # Landmark Visualization\n","      #plt.imshow(image_orig[:, bbox[1] : bbox[3], bbox[0] : bbox[2]].movedim(0, 2).cpu())\n","      #plt.scatter(x = bbox_positions[:, 0], y = bbox_positions[:, 1], c = 'r', marker = 'o', s = 40)\n","      #plt.scatter(x = landmarks[[i for i in range(0, 34, 2)]] - bbox[0].cpu(), y = landmarks[[i for i in range(1, 34, 2)]] - bbox[1].cpu(), c = 'b', marker = 'x', s = 40)\n","      #plt.show()\n","    torch.save(mpjpe, '/content/drive/Shareddrives/OpenMonkeyChallenge/our_mpjpe.pt')"],"metadata":{"id":"UopUMxD8XU_U"},"execution_count":null,"outputs":[]}]}